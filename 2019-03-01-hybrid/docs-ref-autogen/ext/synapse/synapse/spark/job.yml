### YamlMime:AzureCLIGroup
uid: ext_synapse_az_synapse_spark_job
name: az synapse spark job
extensionInformation: >-
  > [!Note]

  > Cette référence fait partie de l’extension **Synapse** pour Azure CLI et requiert la version 2.0.67 ou ultérieure.  L’extension est automatiquement installée la première fois que vous exécutez une commande **AZ Synapse Spark Job** .  [Apprenez-en davantage](https://docs.microsoft.com/en-us/cli/azure/azure-cli-extensions-overview) sur les extensions.
summary: Gérer les travaux de traitement par lots de Synapse Spark.
description: ''
directCommands:
- uid: ext_synapse_az_synapse_spark_job_cancel
  name: az synapse spark job cancel
  summary: Annuler un travail Spark.
  description: ''
  syntax: >-
    az synapse spark job cancel --livy-id
                                --spark-pool-name
                                --workspace-name
                                [--yes]
  examples:
  - summary: Annuler un travail Spark.
    syntax: az synapse spark job cancel --livy-id 1 --workspace-name testsynapseworkspace --spark-pool-name testsparkpool
  requiredParameters:
  - isRequired: true
    name: --livy-id
    summary: ID de la tâche Spark.
    description: ''
  - isRequired: true
    name: --spark-pool-name
    summary: Nom du pool Spark.
    description: ''
  - isRequired: true
    name: --workspace-name
    summary: Nom de l’espace de travail.
    description: ''
  optionalParameters:
  - name: --yes -y
    summary: Ne pas demander de confirmation.
    description: ''
- uid: ext_synapse_az_synapse_spark_job_list
  name: az synapse spark job list
  summary: Répertorie tous les travaux Spark.
  description: ''
  syntax: >-
    az synapse spark job list --spark-pool-name
                              --workspace-name
                              [--from-index]
                              [--size]
  examples:
  - summary: Répertorie tous les travaux Spark.
    syntax: az synapse spark job list --workspace-name testsynapseworkspace --spark-pool-name testsparkpool
  requiredParameters:
  - isRequired: true
    name: --spark-pool-name
    summary: Nom du pool Spark.
    description: ''
  - isRequired: true
    name: --workspace-name
    summary: Nom de l’espace de travail.
    description: ''
  optionalParameters:
  - name: --from-index
    summary: Paramètre facultatif spécifiant l’index à partir duquel la liste doit commencer.
    description: ''
  - name: --size
    summary: Taille de la liste retournée. Par défaut, il s’agit de 20 et il s’agit de la valeur maximale.
    description: ''
- uid: ext_synapse_az_synapse_spark_job_show
  name: az synapse spark job show
  summary: Obtenir un travail Spark.
  description: ''
  syntax: >-
    az synapse spark job show --livy-id
                              --spark-pool-name
                              --workspace-name
  examples:
  - summary: Obtenir un travail Spark.
    syntax: az synapse spark job show --livy-id 1 --workspace-name testsynapseworkspace --spark-pool-name testsparkpool
  requiredParameters:
  - isRequired: true
    name: --livy-id
    summary: ID de la tâche Spark.
    description: ''
  - isRequired: true
    name: --spark-pool-name
    summary: Nom du pool Spark.
    description: ''
  - isRequired: true
    name: --workspace-name
    summary: Nom de l’espace de travail.
    description: ''
- uid: ext_synapse_az_synapse_spark_job_submit
  name: az synapse spark job submit
  summary: Soumettre un travail Spark.
  description: ''
  syntax: >-
    az synapse spark job submit --executor-size {Large, Medium, Small}
                                --executors
                                --main-class-name
                                --main-definition-file
                                --name
                                --spark-pool-name
                                --workspace-name
                                [--archives]
                                [--command-line-arguments]
                                [--configuration]
                                [--language {CSharp, PySpark, Python, Scala, Spark, SparkDotNet}]
                                [--reference-files]
                                [--tags]
  examples:
  - summary: Soumettre un travail Java Spark.
    syntax: >-
      az synapse spark job submit --name WordCount_Java --workspace-name testsynapseworkspace \

      --spark-pool-name testsparkpool \

      --main-definition-file abfss://testfilesystem@testadlsgen2.dfs.core.windows.net/samples/java/wordcount/wordcount.jar \

      --main-class-name WordCount \

      --command-line-arguments abfss://testfilesystem@testadlsgen2.dfs.core.windows.net/samples/java/wordcount/shakespeare.txt \

      abfss://testfilesystem@testadlsgen2.dfs.core.windows.net/samples/java/wordcount/result/ \

      --executors 2 --executor-size Small
  requiredParameters:
  - isRequired: true
    name: --executor-size
    parameterValueGroup: Large, Medium, Small
    summary: Taille de l’exécuteur.
    description: ''
  - isRequired: true
    name: --executors
    summary: Nombre d’exécuteurs.
    description: ''
  - isRequired: true
    name: --main-class-name
    summary: L’identificateur complet ou la classe principale qui se trouve dans le fichier de définition principal.
    description: ''
  - isRequired: true
    name: --main-definition-file
    summary: Fichier principal utilisé pour le travail.
    description: ''
  - isRequired: true
    name: --name -n
    summary: Nom du travail Spark.
    description: ''
  - isRequired: true
    name: --spark-pool-name
    summary: Nom du pool Spark.
    description: ''
  - isRequired: true
    name: --workspace-name
    summary: Nom de l’espace de travail.
    description: ''
  optionalParameters:
  - name: --archives
    summary: Tableau d’archives.
    description: ''
  - name: --command-line-arguments
    summary: 'Arguments facultatifs pour le travail (Remarque : utilisez les URI de stockage pour les arguments de fichier).'
    description: ''
  - name: --configuration
    summary: La configuration du travail Spark.
    description: ''
  - name: --language
    defaultValue: Scala
    parameterValueGroup: CSharp, PySpark, Python, Scala, Spark, SparkDotNet
    summary: Langue de la tâche Spark.
    description: ''
  - name: --reference-files
    summary: Fichiers supplémentaires utilisés en guise de référence dans le fichier de définition principal.
    description: ''
  - name: --tags
    summary: 'Balises séparées par des espaces : clé [= valeur] [clé [= valeur]...]. Utilisez «» pour effacer les balises existantes.'
    description: ''
commands:
- ext_synapse_az_synapse_spark_job_cancel
- ext_synapse_az_synapse_spark_job_list
- ext_synapse_az_synapse_spark_job_show
- ext_synapse_az_synapse_spark_job_submit
globalParameters:
- name: --debug
  summary: Augmentez le niveau de détail de la journalisation pour afficher tous les journaux de débogage.
- name: --help -h
  summary: Affichez ce message d’aide et quittez.
- name: --only-show-errors
  summary: Afficher uniquement les erreurs, en supprimant les avertissements.
- name: --output -o
  defaultValue: json
  parameterValueGroup: json, jsonc, table, tsv
  summary: Format de sortie.
- name: --query
  summary: Chaîne de requêtes JMESPath. Pour obtenir plus d’informations et des exemples, consultez <a href="http://jmespath.org/">http://jmespath.org/</a>.
- name: --verbose
  summary: Augmentez le niveau de détail de la journalisation. Utilisez --debug pour des journaux de débogage complets.
metadata:
  description: Gérer les travaux de traitement par lots de Synapse Spark.
  ms.openlocfilehash: 7523ac312e785652102322c154c0373a8f096202
  ms.sourcegitcommit: e1faf297ba2cdf2ba7e821fbeedff9c9a724c975
  ms.translationtype: MT
  ms.contentlocale: fr-FR
  ms.lasthandoff: 12/16/2020
  ms.locfileid: "102826769"
